---
title: "STAT 447B PROJECT"
output:
  word_document: default
  html_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(dpi=300,fig.width=7)
library(stringr)
library(dplyr)
library(rpart)
library(rpart.plot)
library(caTools)
library(pROC)
library(reshape2)
library(ggplot2)
library(car)
library(Metrics)
library(caret)
library(randomForest)
options(digits=2)
set.seed(447)
```


```{r}
cars.train <- read.csv("C:/Users/Melody Lo/OneDrive - UBC/Desktop/2022W/STAT 447B/Project/cars.train.csv")
print(c(ncol(cars.train),nrow(cars.train)))

```



### Data Cleaning

```{r}

# CamelCase variables are the ones to be used in the model


# In the initial EDA, we came across a 2017 BMW with an uncredible value for `Kilometers_Driven`. The vehicle is only 5 years old and has over 6 million kms driven and is an extreme value even after all transforms. We will thus remove this observation. 
cars.train[495,]
cars.train = cars.train[-495,] # remove uncredible value

# Initial Errors with Train / Test split: 
# We ran into some problems where the testing dataset has unique values for `Name` (car brand) in which the training dataset did not have (by set.seed(447)). The dataset had single observations for numerous car brands in wWhich prevents us fromt training the algorithm to predict. 
### We will remove these observations here prior to the code that splits our dataset.

which(cars.train$Name=="Bentley") #238
which(cars.train$Name=="Force") # 667,668,669
which(cars.train$Name=="ISUZU") # 2684
which(cars.train$Name=="Lamborghini") #2740
which(cars.train$Name=="Smart") # 5039
which(cars.train$Name=="Ambassador") #1
which(cars.train$body.type=="pickup truck") # 5246, 5247, 5248
which(cars.train$body.type=="truck") #2684,2685
cars.train=cars.train[-c(1,238,667,668,669,2679,2684,2685,2740,5039,5246,5247,5248),]
nrow(cars.train)

# Including the extreme value for BMW, we removed a total of 14 observations
# n = 6002

```

### Data Wrangling
```{r}

# We will rename the individual variables as it provides convenience for removing features in training algorithms.

# The conversion rate we used for INR Lahks to CAD - This step was done to help the interpretation of our audience. 
cars.train$Price=cars.train$Price*1666.49
Price=cars.train$Price
logPrice=log(Price) # log transform for the variable `Price` most approximates the Normal

# 1. `Name` : Brand name of the vehicle
Name=as.factor(cars.train$Name)

# 2. `BodyType` : This was a factor variable that we implemented intended to improve the predictability of our model. This variable was created based on previous knowledge and research. 
unique(cars.train$body.type)
BodyType=as.factor(cars.train$body.type) # Convert into factor

# 3. `Age` : is 2022 (current year) - the `Year` of the car from the original Kaggle dataset. 
Age=cars.train$Age

# 4. `CubeKMsDriven` : The Kilometers Driven of the used car.
cars.train$Kilometers_Driven=strtoi(cars.train$Kilometers_Driven) # Convert string to integer

# 5. `Fuel_Type` : The type of fuel the used vehicle uses. 

# table(cars.train$Fuel_Type) 
 # CNG Diesel    LPG Petrol 
 #  56   3205     10   2745 
# Due to the small amount of observations for `CNG` and `LPG`, we will combine the two classes -- Keep categories as `Diesel` `Petrol` and `Other`.

cars.train$Fuel_Type[cars.train$Fuel_Type=="CNG"]<-"Other"
cars.train$Fuel_Type[cars.train$Fuel_Type=="LPG"]<-"Other"
FuelType=factor(cars.train$Fuel_Type)
table(FuelType)

# 6. `Transmission` : The transmission type of the used vehicle. Takes on categories: `Manual` and `Automatic`.

cars.train$Transmission=as.factor(cars.train$Transmission) # convert to factor
Transmission=cars.train$Transmission
table(Transmission)


# 7. `OwnerType` : Is an english word for the type of the previous owner. For example: `First` indicates the previous owner was the first owner of the current used car. 
table(cars.train$Owner_Type)
       # First Fourth & Above         Second 
       #  4926              9            968 
       # Third 
       #   113 

# We will group together the categories to `First` and `Second & Above`

cars.train$Owner_Type=as.factor(cars.train$Owner_Type) # convert into factor
ntrain=nrow(cars.train)
OwnerType=rep("First",ntrain)
OwnerType[cars.train$Owner_Type=="Second"|cars.train$Owner_Type=="Third"|cars.train$Owner_Type=="Fourth & Above"] ="Second & Above"
OwnerType=as.factor(OwnerType)
cars.train$Owner_Type=OwnerType
table(OwnerType) # Post-grouping

# 8. `Mileage` : The mileage of the used car. 
cars.train$Mileage = str_extract(cars.train$Mileage,pattern="(\\w+)") # extract the number only.
cars.train$Mileage = as.numeric(cars.train$Mileage) # turn into numeric class
Mileage=cars.train$Mileage

# 9.`Engine` : is the engine CC of the used car.
cars.train$Engine = str_extract(cars.train$Engine,pattern="(\\w+)") # extract the number only.
cars.train$Engine=strtoi(cars.train$Engine) # String to integer

# 10. `Power` : The power of the used car
cars.train$Power=cars.train$Power
cars.train$Power = strtoi(str_extract(cars.train$Power,"(\\w+)"))
cars.train$Power=as.numeric(cars.train$Power)

# 11. `Seats` : The number of seats in the used car.
# We group the categories into 2, 4, 5, and 6 & Above due to the unbalance
  #  2    4    5    6    7    8    9   10 
  # 16   98 5055   31  674  134    3    5 
Seats=rep("2",ntrain)
Seats[cars.train$Seats=="4"]="4";Seats[cars.train$Seats=="5"]="5"; Seats[cars.train$Seats=="6"|cars.train$Seats=="7"|cars.train$Seats=="8"|cars.train$Seats=="9"|cars.train$Seats=="10"]="6 & Above"
Seats=as.factor(Seats)
cars.train$Seats=Seats
table(Seats)


```

### Transforms
```{r}

# We will attempt to transform variables that are skewed using cube, sqrt, and log transforms. We will use the transform for the variable that most approximates the normal.

# Engine
par(mfrow=c(1,3))
hist((cars.train$Engine)^(1/3)) 
hist(sqrt(cars.train$Engine))
hist(log(cars.train$Engine)) # most normal
LogEngine=log(cars.train$Engine)

# Power

par(mfrow=c(1,3))
hist(sqrt(cars.train$Power)) # most normal
hist(cars.train$Power^(1/3))
hist(log(cars.train$Power)) 
SqrtPower=sqrt(cars.train$Power)


# CubeKMsDriven


par(mfrow=c(1,3))
hist(sqrt(cars.train$Kilometers_Driven)) 
hist(cars.train$Kilometers_Driven^(1/3))
hist(log(cars.train$Kilometers_Driven)) 


Math.cbrt <- function(x) {
    sign(x) * abs(x)^(1/3)
}
CubeKMsDriven=Math.cbrt(cars.train$Kilometers_Driven)


```

#### Mutating Dataset 
For convenience, we will create a dataframe for the transformed and grouped variables.
```{r}

df = data.frame(logPrice,
                Name=cars.train$Name,BodyType=cars.train$body.type,Age,
                CubeKMsDriven,FuelType, Transmission, OwnerType,Mileage,
                LogEngine = log(cars.train$Engine),SqrtPower=sqrt(cars.train$Power),Seats)



```



### Cross-validation training with 3 folds

```{r, echo=TRUE}

library(modelr)
set.seed(447)
k=3
cv=modelr::crossv_kfold(df,k)
traindata=cv[[1]]
testdata=cv[[2]]
for(i in 1:k){
    traindata[[i]]=data.frame(traindata[[i]])
    testdata[[i]]=data.frame(testdata[[i]])
}


```

### Linear Regresion

#### Important Variables Selection

```{r,echo=TRUE}


model0=c()
model.all=c()
for(i in 1:k){
  model0[[i]]=lm(logPrice~1, data=traindata[[i]])
  model.all[[i]]=lm(logPrice ~.,data=traindata[[i]])
}


# Backward Elimination

model_back=c()
for(i in 1:k){
  model_back[[i]]=step(model.all[[i]],direction = "backward",trace=1)
}

# Forward Selection

model_forward=c()
for(i in 1:k){
  model_forward[[i]]=step(model0[[i]],direction = "forward",trace=1, scope = ~ Name+BodyType+CubeKMsDriven+FuelType+Transmission+OwnerType+Mileage+LogEngine+SqrtPower+Seats+Age)
}

# Both

model_both=c()
for(i in 1:k){
  model_both[[i]]=step(model0[[i]],direction = "both",trace = 1, scope = ~ Name+BodyType+CubeKMsDriven+FuelType+Transmission+OwnerType+Mileage+LogEngine+SqrtPower+Seats+Age)
}

# Summary and check the variables left

print(model_back)
print(model_forward)
print(model_both)


# Three methods give the same model with all variables kept whose AIC is the smallest. Hence, we apply all the predictors to the linear regression and check the performance by RMSE and MAE. 

```


### Linear Regression with all variables (k=3)

```{r, echo=TRUE}

lm=c()
for(i in 1:k){
  lm[[i]]=lm(formula = logPrice ~ SqrtPower + Name + Age + BodyType + CubeKMsDriven + 
    FuelType + Mileage + Transmission + Seats + LogEngine + OwnerType, data = traindata[[i]])
}


for (i in 1:length(traindata)){
print(summary(lm[[i]]))
}

```

### Checking Assumptions

```{r,echo=TRUE}
# To avoid bunch of plots, we generally use the model of fold 1 to prove the assumption of linear regression. 

# linearity

plot(lm[[1]],1)

# The residual plot shows a fitted pattern. That is, the red line is approximately horizontal at zero. The presence of this pattern indicates the linearity of model.

# Homoscedasticity

plot(lm[[1]],3)

# The plot shows that residuals approximately spreads out at the same distance throughout the range of fitted value. Hence, we assume the variance of residuals are unchanged which is homoscedasticity.

# Normality of Residuals

plot(lm[[1]],2)

# Residuals are falling approximately along the main line, so we assume residuals are normally distributed.

# Multicollinearity


barchart(sqrt(car::vif(lm[[1]])[,3]),
main = "Multicollinearity",
ylab = "Predictors",
xlab = "squared scaled GVIF",
names.arg = c("Power", "Name", "Age", "Body Type", "Kilometers Driven", "Fuel Type", "Mileage","Transmission","Seats","Engine","OwnerType"),
col = "lightblue",
horiz = TRUE)

# For categorical predictors, we use squared scaled CVIF instead of VIF to measure multicollinearity among predictors. If squared scaled GVIF is less than 4, then we assume there is no multicollinearity. 

```

### MAE and RMSE Check 

```{r,echo=TRUE}

# Build function

# RMSE
# using caret library

Rmse=function(data,model,k){
  x=c()
  for(i in 1:k){
  x[i]=RMSE(data[[i]]$logPrice,model[[i]]$fitted.values)
  }
  print(x)
}

# MAE
# using Metrics library

Mae=function(data,model,k){
  x=c()
  for(i in 1:k){
  x[i]=Metrics::mae(data[[i]]$logPrice,model[[i]]$fitted.values)
  }
  print(x)
}


```

### Out-sample Predictions

```{r,echo=TRUE}

# build Interval Score function

intervalScore = function(predObj,actual,level)
{ n = nrow(predObj)
alpha = 1-level
actual=exp(actual)
predObj=exp(predObj)
ilow = (actual<predObj[,2]) # overestimation
ihigh = (actual>predObj[,3]) # underestimation
sumlength = sum(predObj[,3]-predObj[,2]) # sum of lengths of prediction intervals
sumlow = sum(predObj[ilow,2]-actual[ilow])*2/alpha
sumhigh = sum(actual[ihigh]-predObj[ihigh,3])*2/alpha
avglength = sumlength/n
IS = (sumlength+sumlow+sumhigh)/n # average length + average under/over penalties
cover = mean(actual>= predObj[,2] & actual<=predObj[,3])
summ = c(level,avglength,IS,cover)
# summary with level, average length, interval score, coverage rate
imiss = which(ilow | ihigh)
list(summary=summ, imiss=imiss)
}

# Build out-of-sample predictions function

outPRedIS=function(model,k){
  outpredLm50=c()
  outpredLm80=c()
  for(i in 1:k){
  outpredLm50[[i]]=predict(model[i],newdata = testdata[[i]], interval = "prediction", level = 0.5)
  outpredLm80[[i]]=predict(model[i],newdata = testdata[[i]], interval = "prediction", level = 0.8)
  }
  
  for(i in 1:k){
  outpred50=data.frame(outpredLm50[[i]])
  outpred80=data.frame(outpredLm80[[i]])
  OSLM50=intervalScore(outpred50,(testdata[[i]]$logPrice),0.5)
  OSLM80=intervalScore(outpred80,(testdata[[i]]$logPrice),0.8)
  outLM=rbind(OSLM50$summary,OSLM80$summary)
  colnames(outLM)=c("level","avgleng","IS","cover")
  print(outLM)
  }
}

```
### Linear Regression with all variables

```{r,echo=TRUE}
# check performance
Rmse(traindata,lm,3)
Mae(traindata,lm,3)
outPRedIS(lm,3)


```

### Visualizing Actual and Predicted

```{r,echo=TRUE}

## Plot to show the similarity of actual to predicted prices.
pred.vs.actual.plot=function(model,k){
outpredLm50=c()
outpredLm80=c()
  outpredLm50[[k]]=predict(model[[k]],newdata = testdata[[k]], interval = "prediction", level = 0.5)
  outpredLm80[[k]]=predict(model[[k]],newdata = testdata[[k]], interval = "prediction", level = 0.8)


  dfLm50=data.frame(outpredLm50[[k]])
  dfLm80=data.frame(outpredLm80[[k]])
  predLm50=exp(dfLm50[,1]) # e^logPrice
  predLm80=exp(dfLm80[,1]) # e^logPrice
  LmDF50=data.frame(pred=predLm50,actual=exp(testdata[[k]]$logPrice))
  LmDF80=data.frame(pred=predLm80,actual=exp(testdata[[k]]$logPrice))


LmDF1 = LmDF50 %>% mutate(rowid=row_number())
LmDF1 = melt(LmDF1,id.vars="rowid")

print(ggplot(LmDF1,aes(x=rowid,y=value,colour=variable)) + geom_line() + geom_point() + labs(x="Predicted Values",y="Actual Values",title="Predicted vs Actual Used Car Prices (CV)"))

print(ggplot(LmDF50,aes(x=predLm50,y=testdata[[k]]$logPrice)) + geom_abline() + geom_point() + labs(x="Predicted Values",y="Actual Values",title="Predicted vs Actual Used Car Prices (CV)"))

LmDF2 = LmDF80 %>% mutate(rowid=row_number())
LmDF2 = melt(LmDF2,id.vars="rowid")

print(ggplot(LmDF2,aes(x=rowid,y=value,colour=variable)) + geom_line() + geom_point() + labs(x="Predicted Values",y="Actual Values",title="Predicted vs Actual Used Car Prices (CV)"))

print(ggplot(LmDF80,aes(x=predLm80,y=testdata[[k]]$logPrice)) + geom_abline() + geom_point() + labs(x="Predicted Values",y="Actual Values",title="Predicted vs Actual Used Car Prices (CV)"))

}

for (i in 1:k){
  pred.vs.actual.plot(lm,k)
}



```

### Lineae Regression with Subset 1 (k=3)

We saw earlier that the variable `Seats` is not significant thus we will try subsetting the dataset.
```{r,echo=TRUE}


lm2=c()
for(i in 1:k){
  lm2[[i]]=lm(formula = logPrice ~ SqrtPower + Name + Age + BodyType + CubeKMsDriven + FuelType + Mileage + Transmission + LogEngine + OwnerType, data = traindata[[i]])
}

# check performance
Rmse(traindata,lm2,3)
Mae(traindata,lm2,3)
outPRedIS(lm2,3)

```
### Visualizing Actual and Predicted

```{r,echo=TRUE}

for (i in 1:k){
  pred.vs.actual.plot(lm2,k)
}

```


### Linear Rggression with Subset 2 (k=3)

Based on Regression tree outputs, we will use only variables `Age`,`Name` and `SqrtPower`

```{r,echo=TRUE}

lm3=c()
for(i in 1:k){
  lm3[[i]]=lm(logPrice~Name+Age+SqrtPower, data = traindata[[i]])
}

# check performance
Rmse(traindata,lm3,3)
Mae(traindata,lm3,3)
outPRedIS(lm3,3)
```
### Visualizing Actual and Predicted

```{r,echo=TRUE}

for (i in 1:k){
  pred.vs.actual.plot(lm3,k)
}

```

### Cross-validation training with 5 folds

```{r, echo=TRUE}

library(modelr)
set.seed(447)
k=5
cv=modelr::crossv_kfold(df,k)
traindata=cv[[1]]
testdata=cv[[2]]
for(i in 1:k){
    traindata[[i]]=data.frame(traindata[[i]])
    testdata[[i]]=data.frame(testdata[[i]])
}


```

### Linear Regresion with all variables (k=5)

#### Important Variables Selection

For k=5, no predictors are eliminated that the regression model with all variables still has the smallest AIC. 
```{r,echo=TRUE,results='hide'}


model0=c()
model.all=c()
for(i in 1:k){
  model0[[i]]=lm(logPrice~1, data=traindata[[i]])
  model.all[[i]]=lm(logPrice ~.,data=traindata[[i]])
}


# Backward Elimination

model_back=c()
for(i in 1:k){
  model_back[[i]]=step(model.all[[i]],direction = "backward",trace=1)
}

# Forward Selection

model_forward=c()
for(i in 1:k){
  model_forward[[i]]=step(model0[[i]],direction = "forward",trace=1, scope = ~ Name+BodyType+CubeKMsDriven+FuelType+Transmission+OwnerType+Mileage+LogEngine+SqrtPower+Seats+Age)
}

# Both

model_both=c()
for(i in 1:k){
  model_both[[i]]=step(model0[[i]],direction = "both",trace = 1, scope = ~ Name+BodyType+CubeKMsDriven+FuelType+Transmission+OwnerType+Mileage+LogEngine+SqrtPower+Seats+Age)
}

# Summary and check the variables left

print(model_back)
print(model_forward)
print(model_both)

# Just like k=3, three methods give the same result of all variables kept whose AIC is the smallest.

```


# Linear Regression wtih all variables (k=5)
```{r,echo=TRUE}

lm=c()
for(i in 1:k){
  lm[[i]]=lm(formula = logPrice ~ SqrtPower + Name + Age + BodyType + CubeKMsDriven + 
    FuelType + Mileage + Transmission + Seats + LogEngine + OwnerType, data = traindata[[i]])
}

# check performance
Rmse(traindata,lm,5)
Mae(traindata,lm,5)
outPRedIS(lm,5)
```

### Visualizing Actual and Predicted

```{r,echo=TRUE}

for (i in 1:k){
  pred.vs.actual.plot(lm,k)
}

```

#### Linear Regression with Subset 1 (k=5)

Linear Rgeression without Seats. 
```{r,echo=TRUE}


lm2=c()
for(i in 1:k){
  lm2[[i]]=lm(formula = logPrice ~ SqrtPower + Name + Age + BodyType + CubeKMsDriven + FuelType + Mileage + Transmission + LogEngine + OwnerType, data = traindata[[i]])
}


# check performance
Rmse(traindata,lm2,5)
Mae(traindata,lm2,5)
outPRedIS(lm2,5)

```
### Visualizing Actual and Predicted

```{r,echo=TRUE}

for (i in 1:k){
  pred.vs.actual.plot(lm2,k)
}

```

### Linea Regression with Subset 2 (k=5)

Regression tree with Name, Age and SqrtPower 

```{r,echo=TRUE}

lm3=c()
for(i in 1:k){
  lm3[[i]]=lm(logPrice~Name+Age+SqrtPower, data = traindata[[i]])
}


# check performance
Rmse(traindata,lm3,5)
Mae(traindata,lm3,5)
outPRedIS(lm3,5)
```
### Visualizing Actual and Predicted

```{r,echo=TRUE}

for (i in 1:k){
  pred.vs.actual.plot(lm3,k)
}

```

Given the all metrics of k=3 and k=5 CV, we can conclude that the regression linear with all variables gives the best performance on predicting the price of used cars in India among the regresion models.



